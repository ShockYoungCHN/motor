import json
import re
import pexpect
import time, os
from threading import Thread
from device import find_device_index
from ib_counters import IBCounterMonitor

######################################### utils ####################################################
packages = {
    "libibverbs": "libibverbs-dev",
    "pthread": "build-essential",
    "boost_coroutine": "libboost-coroutine-dev",
    "boost_context": "libboost-context-dev",
    "boost_system": "libboost-system-dev",
    "cmake": "cmake"
}


# spare the efforts for add -i to every scp command
def generate_ssh_config(username, private_key_path, ssh_config_file):
    os.makedirs(os.path.dirname(ssh_config_file), exist_ok=True)

    ssh_config_content = f"""
# SSH Config generated by script

Host 192.168.*.* node*
  User {username}
  IdentityFile {private_key_path}
"""

    with open(ssh_config_file, 'a') as config_file:
        config_file.write(ssh_config_content)

    print(f"SSH config updated at {ssh_config_file}")


def replace_in_file(filename, pattern, replacement):
    with open(filename, 'r') as file:
        content = file.read()

    content = re.sub(pattern, replacement, content)

    with open(filename, 'w') as file:
        file.write(content)


def install_package(child, package_name):
    try:
        # cloudlab sudo need no password
        child.sendline(f"sudo apt-get install -y {package_name}")
        child.expect("\$ ", timeout=600)
        output = child.before.decode('utf-8').lower()
        if "unable to locate package" in output or "error" in output:
            print(f"Error installing {package_name}.")
        else:
            print(f"{package_name} installed successfully.")
    except pexpect.exceptions.ExceptionPexpect as e:
        print(f"An error occurred during installation: {e}")


def check_and_install_packages(child):
    for package in packages:
        install_package(child, packages[package])


def sync_files(src_path, dest_path, username, ip):
    print(f"scp -r {src_path} {username}@{ip}:{dest_path}")
    os.system(f"scp -r {src_path} {username}@{ip}:{dest_path}")


def create_ssh_session(hostname, username, private_key_path):
    ssh_newkey = 'Are you sure you want to continue connecting'
    success = 'Welcome to Ubuntu'
    # keepalive is important!
    child = pexpect.spawn(f'ssh -o TCPKeepAlive=yes -i {private_key_path} {username}@{hostname}')
    i = child.expect([success, ssh_newkey, pexpect.TIMEOUT, pexpect.EOF, 'password:', pexpect.exceptions.EOF])

    if i == 1:
        child.sendline('yes')
        i = child.expect(success)
        if i != 0:
            print("Unable to connect to the host.")
            return None
    elif i == 0:
        pass
    else:
        print("Unable to connect to the host.")
        return None
    child.before = ''
    child.after = ''
    return child


def close_ssh_sessions(children):
    for child in children:
        child.close()


#############################################################################################

def generate_combinations(range_threads, range_coroutines):
    return [(num_threads, num_coroutines) for num_threads in range_threads for num_coroutines in range_coroutines]


# modify the workload in flags.h; all mn share the same flags.h
def configure_flags(flag_path, memory_pool_hosts, workload, backup_num):
    workloads = {
        'tpcc': 'WORKLOAD_TPCC',
        'tatp': 'WORKLOAD_TATP',
        'smallbank': 'WORKLOAD_SmallBank',
        'micro': 'WORKLOAD_MICRO'
    }
    if workload not in workloads:
        raise ValueError(f"Invalid workload type: {workload}. Choose from {list(workloads.keys())}.")

    for wl in workloads:
        if wl == workload:
            replacement_str = f"#define {workloads[wl]} 1"
        else:
            replacement_str = f"#define {workloads[wl]} 0"
        workload_pattern = f'#define {workloads[wl]} (\d+)'
        replace_in_file(flag_path, workload_pattern, replacement_str)

    replace_in_file(flag_path, r'#define BACKUP_NUM (\d+)', f"#define BACKUP_NUM {backup_num}")

    for ip in memory_pool_hosts:
        sync_files(flag_path, flag_path, username, ip)


# gen the mn_config.json for each node
def configure_mn_config(config_path, memory_node_ips, memory_node_ids, memory_node_ip, memory_node_id, workload):
    with open(config_path, 'r') as file:
        config_data = json.load(file)

    config_data["other_memory_nodes"]["memory_node_ips"] = memory_node_ips
    config_data["other_memory_nodes"]["memory_node_ids"] = memory_node_ids
    config_data["other_memory_nodes"]["memory_node_ports"] = config_data["other_memory_nodes"]["memory_node_ports"][
                                                             0:len(memory_node_ips)]
    config_data["local_memory_node"]["machine_id"] = memory_node_id
    config_data["local_memory_node"]["machine_num"] = len(memory_node_ips)
    config_data["local_memory_node"]["reserve_GB"] = MEM_GB
    config_data["local_memory_node"]["dev_id"] = device.device_index
    config_data["local_memory_node"]["port"] = device.port_num
    config_data["local_memory_node"]["per_thread_delta_size_MB"] = delta_size
    workloads_to_upper_case = {
        'tpcc': 'TPCC',
        'tatp': 'TATP',
        'smallbank': 'SmallBank',
        'micro': 'MICRO'
    }
    if "local_memory_node" in config_data and "workload" in config_data["local_memory_node"]:
        config_data["local_memory_node"]["workload"] = workloads_to_upper_case[workload]

    # mn_config_%d.json
    with open(f"{config_path.split('.')[0]}_{memory_node_id}.json", 'w') as file:
        json.dump(config_data, file, indent=4)
    sync_files(f"{config_path.split('.')[0]}_{memory_node_id}.json", config_path, username, memory_node_ip)
    # also sync the workload config
    sync_files(wl_config(workload), wl_config(workload), username, memory_node_ip)


# assume there is only on cn, so id is always 0, ["local_memory_node"]["machine_num"] always 1
def configure_cn_config(config_path, memory_node_ips):
    with open(config_path, 'r') as file:
        config_data = json.load(file)

    config_data["remote_mem_nodes"]["remote_ips"] = memory_node_ips
    config_data["remote_mem_nodes"]["remote_ports"] = [config_data["remote_mem_nodes"]["remote_ports"][0]] * len(
        memory_node_ips)
    config_data["remote_mem_nodes"]["remote_meta_ports"] = ([config_data["remote_mem_nodes"]["remote_meta_ports"][0]]
                                                            * len(memory_node_ips))
    config_data["local_compute_node"]["dev_id"] = device.device_index
    config_data["local_compute_node"]["port"] = device.port_num
    with open(config_path, 'w') as file:
        json.dump(config_data, file, indent=4)

def configure_workload(wl_config_path, wl):
    with open(wl_config_path, 'r') as file:
        config_data = json.load(file)

    config_data[wl]["attempted_num"] = ATTEMPTS

    with open(wl_config_path, 'w') as file:
        json.dump(config_data, file, indent=4)

def start_memory_pool(child):
    try:
        cd_command = f'cd ~/{txn}/build/memory_pool/server' if txn == "ford" else f'cd ~/{txn}/build/memory_node/server'
        start_command = f'numactl --cpunodebind={NUMA} --membind={NUMA} ./zm_mem_pool' if txn == "ford" else f'numactl --cpunodebind={NUMA} --membind={NUMA} ./motor_mempool'

        child.sendline(cd_command)
        child.expect_exact('$')
        child.sendline(start_command)
        # this usually takes 2 minutes, extend the timeout in case
        child.expect("Server listen", timeout=480)
        print("Memory node started successfully")
    except pexpect.EOF:
        print("Failed to start memory pool.")
    except pexpect.TIMEOUT:
        print("Timeout waiting for memory pool to start.")

def refresh_memory_pool(child):
    try:
        child.sendline('c')
        child.expect("Server listen", timeout=480)
    except pexpect.TIMEOUT:
        print(f"Timeout waiting for response in {child}")
    except pexpect.EOF:
        print(f"EOF encountered with {child}")
    except Exception as e:
        print(f"Error refresh mem node: {e}")


def quit_memory_pool(child, force=False):
    if force:
        child.sendline("sudo pkill -f motor_mempool")
        child.sendline("sudo pkill -f zm_mem_pool")
        time.sleep(3)
        return

    try:
        child.sendline('q')
        child.expect("Free mr", timeout=480)
    except pexpect.TIMEOUT:
        print(f"Timeout waiting for response in {child}")
    except pexpect.EOF:
        print(f"EOF encountered with {child}")
    except Exception as e:
        print(f"Error: {e} with {child}")

def run_command(child, command, expect_str="DONE"):
    try:
        child.sendline(command)
        child.expect(expect_str, timeout=600)
        # print(child.before.decode())
        # print(child.after.decode())
        print(f"{command} executed successfully")
    except pexpect.EOF:
        print(f"{command} execution failed.")
    except pexpect.TIMEOUT:
        print("Timeout during command execution.")

def run_workload_in_cluster(compute_child, memory_pool_children, txn, workload, epoch, thr_coro_combinations):
    print("Configuring memory & compute nodes ...")
    configure_flags(proj_flags, memory_pool_hosts, workload, backup_num)
    configure_workload(wl_config(workload), workload)
    for (id, ip) in enumerate(memory_pool_hosts):
        configure_mn_config(proj_mn_config, memory_pool_hosts, list(range(mn_cnt)), ip, id, workload)
    configure_cn_config(proj_cn_config, memory_pool_hosts)
    build_cmd = f"cd {proj_root} && {proj_root}/build.sh"+(" -d" if DEBUG else "")
    pool_threads = [Thread(target=run_command, args=(child,
                                                     build_cmd,
                                                     "-------------------- build finish ----------------------",))
                    for child in memory_pool_children+[compute_child]]

    for child in pool_threads:
        child.start()
    for thread in pool_threads:
        thread.join()

    print("Starting memory pools...")
    pool_threads = [Thread(target=start_memory_pool, args=(child,)) for child in memory_pool_children]
    for thread in pool_threads:
        thread.start()
    for thread in pool_threads:
        thread.join()
    print("All nodes in the memory pool started successfully")

    for i in range(epoch):
        # start to run in compute node
        for j, (threads, coroutines) in enumerate(thr_coro_combinations):
            # construct the command
            command = f"numactl --cpunodebind={NUMA} --membind={NUMA} ./run {workload} {txn} {threads} {coroutines}" if txn == "ford" \
                else f"numactl --cpunodebind={NUMA} --membind={NUMA} ./run {workload} {threads} {coroutines} SR"
            if txn == "ford":
                cd_and_run = f'cd {proj_root}/build/compute_pool/run && {command}'
            elif txn == "motor":
                cd_and_run = f'cd {proj_root}/build/compute_node/run && {command}'
            else:
                raise Exception("Invalid transaction type")

            print(f"Running command on compute node: {command}")
            if IB_COUNTERS:
                ibMonitor.start()

            run_command(compute_child, cd_and_run)

            if IB_COUNTERS:
                ibMonitor.end()
                hw_counters_diff, counters_diff = ibMonitor.get_counters_diff()
                print(f"HW Counters diff: {hw_counters_diff}")
                print(f"Counters diff: {counters_diff}")
            print(f"(thread, coroutine): ({threads}, {coroutines}) finished")

            # only refresh memory pool if it's not the last epoch and last combination
            if i == epoch - 1 and (threads, coroutines) == thr_coro_combinations[-1]:
                time.sleep(5)  # wait for a sec so that the last command can append the result to the file
                break
            threads = []
            for child in memory_pool_children:
                thread = Thread(target=refresh_memory_pool, args=(child,))
                threads.append(thread)
                thread.start()

            for thread in threads:
                thread.join()
            print("All nodes in memory pool refreshed successfully")

    print(f"finish workload {workload}, quitting memory pools...")

    pool_threads = [Thread(target=quit_memory_pool, args=(child,)) for child in memory_pool_children]
    for thread in pool_threads:
        thread.start()
    for thread in pool_threads:
        thread.join()
    print("All nodes in memory pool quit successfully")


compute_node_hosts = ["192.168.1.1"]
memory_pool_hosts = ["192.168.1.2", "192.168.1.3", "192.168.1.4"]
username = 'samuraiy'
private_key_path = '/users/samuraiy/id_rsa_cloudlab'
txn = "motor"
mn_cnt = len(memory_pool_hosts)
proj_root = f"/users/samuraiy/{txn}"
proj_cn_config = f"{proj_root}/config/cn_config.json"
proj_mn_config = f"{proj_root}/config/mn_config.json"
wl_config = lambda wl: f"{proj_root}/config/{wl.lower()}_config.json"
proj_flags = f"{proj_root}/txn/flags.h"
NUMA = 0  #on r650 set it to 1. todo: don't forget to change thread binding code!
MEM_GB = 96  # 192GB is default, however 96GB is much faster since 192GB cannot fit in one NUMA
device = find_device_index("192.168.1.0", "255.255.255.0")
delta_size = 50 # default 50MB
ATTEMPTS = 1000_000 # default 1000_000
workloads = ["tpcc", "tatp", "smallbank"]
CORE_DUMP = False
DEBUG = False
IB_COUNTERS = False
EPOCH = 2

combinations = generate_combinations(range(8, 33, 1), range(2, 3, 2))
backup_num = 2  # cannot be 0
ibMonitor = IBCounterMonitor(device.device_name)

if __name__ == '__main__':
    generate_ssh_config(username, private_key_path, '/users/samuraiy/.ssh/config')

    memory_pool_children = [create_ssh_session(host, username, private_key_path) for host in memory_pool_hosts]
    pool_threads = [Thread(target=quit_memory_pool, args=(child, True)) for child in memory_pool_children]
    for thread in pool_threads:
        thread.start()
    for thread in pool_threads:
        thread.join()
    compute_child = pexpect.spawn('bash', echo=False)
    for child in memory_pool_children+[compute_child]:
        check_and_install_packages(child)

    # start logging & core dump
    for child in memory_pool_children:
        child.sendline('script -f motor_mn.log')
        if CORE_DUMP:
            child.sendline('ulimit -c unlimited')
        else:
            child.sendline('ulimit -c 0')
    compute_child.sendline('script -f motor_cn.log')
    if CORE_DUMP:
        compute_child.sendline('ulimit -c unlimited')
    else:
        compute_child.sendline('ulimit -c 0')

    for ip in memory_pool_hosts:
        sync_files(f"{proj_root}", f"{os.path.dirname(proj_root)}", username, ip)
    for wl in workloads:
        run_workload_in_cluster(compute_child, memory_pool_children, txn, wl, EPOCH, combinations)
    compute_child.close()
    for child in memory_pool_children:
        child.close()

# cautious: this script should run in 192.168.1.1(the compute node); other node from 192.168.1.2 are memory nodes
# the repo should be cloned to the proj_root in 192.168.1.1

# also, this script assume the NIC on every node has the same name/index/port number
